[
  {
    "objectID": "quarto_site/index.html",
    "href": "quarto_site/index.html",
    "title": "The STRESS Guidelines: A first update.",
    "section": "",
    "text": "This book reports early results in the first update of the Strengthening the Reporting of Empirical Simulation Studies (STRESS) guidelines for Discrete-Event Simulation, Agent Based Simulation and System Dynamics. Results should be viewed as draft and subject to change.\n\nMonks, T., Currie, C. S. M., Onggo, B. S., Robinson, S., Kunc, M., & Taylor, S. J. E. (2018). Strengthening the reporting of empirical simulation studies: Introducing the STRESS guidelines. Journal of Simulation, 13(1), 55–67. https://doi.org/10.1080/17477778.2018.1442155"
  },
  {
    "objectID": "quarto_site/index.html#about",
    "href": "quarto_site/index.html#about",
    "title": "The STRESS Guidelines: A first update.",
    "section": "",
    "text": "This book reports early results in the first update of the Strengthening the Reporting of Empirical Simulation Studies (STRESS) guidelines for Discrete-Event Simulation, Agent Based Simulation and System Dynamics. Results should be viewed as draft and subject to change.\n\nMonks, T., Currie, C. S. M., Onggo, B. S., Robinson, S., Kunc, M., & Taylor, S. J. E. (2018). Strengthening the reporting of empirical simulation studies: Introducing the STRESS guidelines. Journal of Simulation, 13(1), 55–67. https://doi.org/10.1080/17477778.2018.1442155"
  },
  {
    "objectID": "quarto_site/index.html#project-team",
    "href": "quarto_site/index.html#project-team",
    "title": "The STRESS Guidelines: A first update.",
    "section": "Project team",
    "text": "Project team\n\nConducting the data extraction and analysis\n\nFatemeh Alidoost \n\nProject design, analysis and interpretation:\n\nThomas Monks \nAlison Harper \nNavonil Mustafee \nSimon Taylor"
  },
  {
    "objectID": "quarto_site/index.html#funding",
    "href": "quarto_site/index.html#funding",
    "title": "The STRESS Guidelines: A first update.",
    "section": "Funding",
    "text": "Funding\nThis work was supported by the Medical Research Council grant number MR/Z503915/1"
  },
  {
    "objectID": "quarto_site/index.html#citation",
    "href": "quarto_site/index.html#citation",
    "title": "The STRESS Guidelines: A first update.",
    "section": "Citation",
    "text": "Citation\nTo add…"
  },
  {
    "objectID": "quarto_site/index.html#license",
    "href": "quarto_site/index.html#license",
    "title": "The STRESS Guidelines: A first update.",
    "section": "License",
    "text": "License\nThis repository is licensed under the MIT License.\n\n\n\n\n\n\nView license\n\n\n\n\n\nMIT License\nCopyright (c) 2024 STARS Project Team\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "quarto_site/analysis.html",
    "href": "quarto_site/analysis.html",
    "title": "Analysis (draft)",
    "section": "",
    "text": "This notebook contains the Python script that analyses the data extracted from the STRESS review."
  },
  {
    "objectID": "quarto_site/analysis.html#imports",
    "href": "quarto_site/analysis.html#imports",
    "title": "Analysis (draft)",
    "section": "1. Imports",
    "text": "1. Imports\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom typing import Optional\n\n# use gglot style for all matplotlib\nplt.style.use(\"ggplot\")"
  },
  {
    "objectID": "quarto_site/analysis.html#constants",
    "href": "quarto_site/analysis.html#constants",
    "title": "Analysis (draft)",
    "section": "2. Constants",
    "text": "2. Constants\n\nREVIEW_CSV_FILE_PATH = \"PY_STRESS.csv\""
  },
  {
    "objectID": "quarto_site/analysis.html#utility-functions",
    "href": "quarto_site/analysis.html#utility-functions",
    "title": "Analysis (draft)",
    "section": "3. Utility functions",
    "text": "3. Utility functions\nSome simple functions repeatedly used for plotting or analysing datasets.\n\n\nCode\ndef frequency_bar_chart(\n    data: pd.DataFrame, \n    x_label: str,\n    y_label: Optional[str] = \"Frequency\",\n    rotate_x_ticks: Optional[int] = 0,\n    figsize: Optional[int|int] = (12,6)\n):\n    '''\n    Create bar chart of the selected categorical variable.\n    Returns matplotlib figure and axis.\n\n    Parameters:\n    ---------\n    data: pd.DataFrame\n       Frequency dataset for bar chart\n\n    x_label: str\n        Label to display on x-axis\n\n    y_label: str, optional (default = \"Frequency\")\n        Label to display on y-axis\n\n    rotate_x_ticks: int, optional (default = 0)\n        Degress to rotate the x axis text (0 for no rotation)\n\n    figsize: Tuple(int, int), optional (default=(12,6)\n        The size of the matplotlib picture.\n\n    Returns:\n    -------\n    out: fig and axis of plot\n    '''\n\n    fig = plt.figure(figsize=figsize)\n    ax = fig.add_subplot()\n    \n    ax = data.plot(kind=\"bar\", ax=ax)\n\n    _ = ax.set_xlabel(x_label)\n    _ = ax.set_ylabel(y_label)\n    \n    # Add data labels on the bars\n    _ = ax.bar_label(ax.containers[0], label_type=\"edge\", padding=3)\n\n    # rotate x axis text\n    _ = plt.xticks(rotation=rotate_x_ticks)\n    \n    return fig, ax"
  },
  {
    "objectID": "quarto_site/analysis.html#read-in-review-data",
    "href": "quarto_site/analysis.html#read-in-review-data",
    "title": "Analysis (draft)",
    "section": "4. Read in review data",
    "text": "4. Read in review data\n\nNote this data collected in Excel.\n\n\n\n\n\n\n\nTM Queries about data\n\n\n\n\n\n\nTM query (1): can we drop column index 27? This is labelled 27 and is all values are null. I’ve removed it in the code below…\nTM query (2): there were three blank lines at the end of the CSV. I’ve removed this in the updated load routine.\nTM query (3): what does DP mean in “used?”\nTM query (4): target authors: is this a manual field you have included? or did you have a formula in Excel? It appears to be different from your calculation at the end?\nTM query (5): To discuss with others -&gt; I think we should just exclude all studies not in English.\n\n\n\n\n\n4.1 Data cleaning functions\nSmaller function used by the main pipeline to load the dataset.\n\n\nCode\ndef recode_whitespace(df: pd.DataFrame) -&gt; pd.DataFrame:\n    '''\n    recode whitespace as \"_\" and strip head/tail whitespace just in case\n    '''\n    # strip leading and lagging white space\n    df.columns = df.columns.str.strip()\n    # replace remaining whitespace with \"_\"\n    df.columns = df.columns.str.replace(\" \", \"_\")\n    return df\n\n\ndef strip_punctuation(df: pd.DataFrame) -&gt; pd.DataFrame:\n    '''\n    strip select punction from column headers\n    '''\n    df.columns = df.columns.str.replace(\"?\", \"\")\n    df.columns = df.columns.str.replace(\"'\", \"\")\n    df.columns = df.columns.str.replace(\"-\", \"_\")\n    df.columns = df.columns.str.replace(\"/\", \"\")\n    return df\n\ndef cols_to_lower(df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"\n    Convert all column names in a dataframe to lower case\n\n    Params:\n    ------\n    df - pandas.DataFrame\n\n    Returns:\n    -------\n    out: pandas.DataFrame\n    \"\"\"\n    new_cols = [c.lower() for c in df.columns]\n    df.columns = new_cols\n    return df\n\ndef drop_non_english_language(df: pd.DataFrame) -&gt; pd.DataFrame:\n    '''\n    Check for \"Not in English\" recorded in any column\n    Return all other rows.\n    '''\n    return df[~df.isin(['Not in English']).any(axis=1)]\n\n\n\n\n4.2 Load Data Pipeline\n\n\nCode\ndef load_review_dataset(\n    path: Optional[str] = REVIEW_CSV_FILE_PATH,\n) -&gt; pd.DataFrame:\n    \"\"\"Read full data extraction data set for the review from a CSV file.\n    Returns cleaned dataset.\n\n    Assumes data is stored in .csv\n\n    Cleaning pipeline for dataset:\n    1. drop redunance columns\n    2. drop rows that contain all NAs\n    3. drop rows that are no in English\n    3. rename columns with complex strings\n    4. strip all punctuation from column headers\n    5. column headers to lower case\n    6. replace all whitespace in headers with \"_\"\n    7. convert all blank strings in cells to NaN\n    8. recode variables to be internally consistent in naming\n    9. perform type conversion for integer fields\n    10. type conversion for categorical fields\n    \n\n    Parameters:\n    ----------\n    path: str, optional (default=REVIEW_CSV_FILE_PATH)\n        path or URL for review dataset.\n\n    Returns:\n    --------\n    out: pd.DataFrame\n\n    \"\"\"\n\n    # SETUP FOR DATASET CLEAN\n\n    # cols to drop from data read in\n    cols_to_remove = [\n        \"Unnamed: 0\",\n        \"...27\",\n        \"Questions to be asked from authors / experts\",\n        \"Fatemeh's Note\",\n        \"Note\",\n    ]\n\n    # simple type conversions\n    type_conversions = {\"year\": \"UInt16\"}\n\n    # renaming of columns to names suitable for analysis\n    new_labels = {\n        \"1. Objectives (purpose, model outputs, aims of experimentation)\": \"stress_objectives\",\n        \"2. Logic (base model overview diagram, base model logic, scenario logic, algorithms, components)\": \"stress_logic\",\n        \"3. Data (data sources, input parameters, preprocessing, assumptions\": \"stress_logic\",\n        \"4. Experimentation (initialisation, run length, estimation approach)\": \"stress_exp\",\n        \"5. Implementation (software and programming language, random sampling, model execution, system specification)\": \"stress_imp\",\n        \"6. Code access (computer model sharing statement)\": \"stress_code\",\n    }\n\n    # used to recode variables so they are consistent.\n    recoded_variables = {\"used\": {\"NO\": \"No\"}}\n\n    # DATA CLEANING PIPELINE\n    df = (\n        pd.read_csv(path, index_col=\"No\")\n        # drop redundant index column\n        .drop(labels=cols_to_remove, axis=1)\n        # drop all blank rows (this will remove the blank 3 rows at end of CSV)\n        .dropna(how=\"all\")\n        # drop all studies that do not use an English language\n        .pipe(drop_non_english_language)\n        # rename verbose column headers\n        .rename(columns=new_labels)\n        # remove any punctutation i.e. \"?\" and \"-\"\n        .pipe(strip_punctuation)\n        # all columns headers to lower case\n        .pipe(cols_to_lower)\n        # replace all whitespace with \"_\" in col headers\n        .pipe(recode_whitespace)\n        # replace all whitespace and blank strings in fields with NaN\n        .replace(r\"^\\s*$\", np.nan, regex=True)\n        # recoded variables e.g. used \"NO\" becomes \"No\"\n        .replace(recoded_variables)\n        # update the type of columns to int where needed\n        .astype(type_conversions)\n        # categorical variables\n        .assign(\n            used=lambda x: pd.Categorical(x[\"used\"]),\n            type_of_paper=lambda x: pd.Categorical(x[\"type_of_paper\"]),\n            partially=lambda x: pd.Categorical(x[\"partially\"]),\n            method=lambda x: pd.Categorical(x[\"method\"]),\n            software=lambda x: pd.Categorical(x[\"software\"]),\n            source_code_access=lambda x: pd.Categorical(\n                x[\"source_code_access\"]\n            ),\n            application_area=lambda x: pd.Categorical(x[\"application_area\"]),\n            target_authors=lambda x: pd.Categorical(x[\"target_authors\"]),\n            stress_implementation=lambda x: pd.Categorical(\n                x[\"stress_implementation\"]\n            ),\n            hybridisation=lambda x: pd.Categorical(x[\"hybridisation\"])\n        )\n    )\n    return df\n\n\n\n# read in data.\nclean_review_df = load_review_dataset()\n\n# quick summary of columns\nclean_review_df.info(memory_usage=False)\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 165 entries, 1 to 171\nData columns (total 25 columns):\n #   Column                 Non-Null Count  Dtype   \n---  ------                 --------------  -----   \n 0   publication            165 non-null    object  \n 1   authors                165 non-null    object  \n 2   year                   163 non-null    UInt16  \n 3   type_of_paper          163 non-null    category\n 4   journal                161 non-null    object  \n 5   name_of_univerity      73 non-null     object  \n 6   type_of_study          164 non-null    object  \n 7   pre_prints             165 non-null    object  \n 8   doi                    159 non-null    object  \n 9   used                   161 non-null    category\n 10  partially              71 non-null     category\n 11  target_authors         73 non-null     category\n 12  method                 73 non-null     category\n 13  hybridisation          7 non-null      category\n 14  stress_objectives      70 non-null     object  \n 15  stress_logic           70 non-null     object  \n 16  stress_logic           70 non-null     object  \n 17  stress_exp             70 non-null     object  \n 18  stress_imp             70 non-null     object  \n 19  stress_code            70 non-null     object  \n 20  source_code_access     40 non-null     category\n 21  software               69 non-null     category\n 22  application_area       74 non-null     category\n 23  case_study             72 non-null     object  \n 24  stress_implementation  70 non-null     category\ndtypes: UInt16(1), category(10), object(14)\n\n\n\n# rows and columns n's\nclean_review_df.shape\n\n(165, 25)"
  },
  {
    "objectID": "quarto_site/analysis.html#filter-to-empirical-studies-only",
    "href": "quarto_site/analysis.html#filter-to-empirical-studies-only",
    "title": "Analysis (draft)",
    "section": "5. Filter to empirical studies only",
    "text": "5. Filter to empirical studies only\nHere we separate the studies that have used the STRESS guidelines in second dataframe i.e. limit to studies that have used STRESS for documenting a model. This is stored in a notebook level variable called USED_STRESS\n\nFiltering is done using the ‘used’ field.\n\n\ndef filter_to_application_studies(clean_df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Filter the cleaned dataset down to studies that used stress to report\n    a simulation study.\n\n    # To do: drop \"fatemets_notes\", \"questions...\"\n    \"\"\"\n    # Used?: a Yes/No variable.\n    filtered_df = clean_df[clean_df[\"used\"] == \"Yes\"]\n    return filtered_df\n\n\nUSED_STRESS = filter_to_application_studies(clean_review_df)\n\n\n# number of studies that used STRESS as intended i.e. to document\nUSED_STRESS.shape\n\n(73, 25)"
  },
  {
    "objectID": "quarto_site/analysis.html#results",
    "href": "quarto_site/analysis.html#results",
    "title": "Analysis (draft)",
    "section": "6. Results",
    "text": "6. Results\n\nYear of publication\n\n\n\n\n\n\nTM notes for additional analysis\n\n\n\n\n\n\nTM Query (1): 2024 obviously partial, as it will take us a while to do this study we should update again in 2025 to get all 2024 papers if we can\nTM Query (2): WE should prob show no. citations OVERALL by year as well\n\n\n\n\n\ndef figure_1(data: pd.DataFrame, figsize: Optional[int|int] = (12,6)):\n    '''\n    Create bar chart of publications by year (ordered) \n\n    Parameters:\n    ---------\n    data: pd.DataFrame\n        The cleaned + filtered review data to plot\n\n    figsize = Tuple(int, int)\n        Size of matplotlib figure\n        \n    Returns:\n    -------\n    out: fig and axis of plot\n    '''\n\n    # The frequency of papers that have used STRESS guidelines \n    # based on the publication year\n    year_freq = data[\"year\"].value_counts().sort_index(ascending=True)\n\n    return frequency_bar_chart(data=year_freq, \n                               x_label=\"Year\", \n                               y_label=\"Publications\")\n\n\nfig, ax = figure_1(USED_STRESS, False)\nfig.savefig('./figures/figure_1.png', dpi=300, bbox_inches=\"tight\")\n_ = fig.suptitle(\"Fig 1. Frequency of Empirical Papers over Time\")\n\n\n\n\n\n\n\n\n\n\nSimulation method\n\n\n\n\n\n\nData notes\n\n\n\n\n\nHybrid M&S could be the hybridisation of simulation methods (e.g. SD+DES) or hybridisation of a simulation method with data science approach (e.g. Monte Carlo simulation + Machine learning)\n\n\n\n\ndef figure_2(data: pd.DataFrame, figsize: Optional[int|int] = (12,6)):\n    '''\n    Create bar chart of simulation method used in studies \n\n    Parameters:\n    ---------\n    data: pd.DataFrame\n        The cleaned + filtered review data to plot\n\n    figsize = Tuple(int, int)\n        Size of matplotlib figure\n        \n    Returns:\n    -------\n    out: fig and axis of plot\n    '''\n\n    method_freq = data[\"method\"].value_counts()\n\n    return frequency_bar_chart(data=method_freq, \n                               x_label=\"Method\", \n                               y_label=\"Frequency\")\n\n\nfig, ax = figure_2(USED_STRESS, False)\nfig.savefig('./figures/figure_2.png', dpi=300, bbox_inches=\"tight\")\n_ = fig.suptitle(\"Fig 2. Frequency of Simulation Methods\")\n\n\n\n\n\n\n\n\n\n\nApplication area\n\ndef figure_3(data: pd.DataFrame, figsize: Optional[int|int] = (12,6)):\n    '''Frequency of software/coding language usage as bar chart\n\n    Parameters:\n    ---------\n    data: pd.DataFrame\n        The cleaned + filtered review data to plot\n\n    figsize = Tuple(int, int)\n        Size of matplotlib figure\n        \n    Returns:\n    -------\n    out: fig and axis of plot\n    '''\n\n    freq = data[\"application_area\"].value_counts()\n\n    return frequency_bar_chart(data=freq, \n                               x_label=\"Application area\", \n                               y_label=\"Frequency\", \n                               rotate_x_ticks=90)\n\n\nfig, ax = figure_3(USED_STRESS, False)\nfig.savefig('./figures/figure_3.png', dpi=300, bbox_inches=\"tight\")\n_ = fig.suptitle(\"Fig 3. Application area\")\n\n\n\n\n\n\n\n\n\n\nArticle Type\n\ndef figure_4(data: pd.DataFrame, figsize: Optional[int|int] = (12,6)):\n    '''Frequency of software/coding language usage as bar chart\n\n    Parameters:\n    ---------\n    data: pd.DataFrame\n        The cleaned + filtered review data to plot\n\n    figsize = Tuple(int, int)\n        Size of matplotlib figure\n        \n    Returns:\n    -------\n    out: fig and axis of plot\n    '''\n\n    freq = data[\"type_of_paper\"].value_counts()\n\n    return frequency_bar_chart(data=freq, \n                               x_label=\"Application area\", \n                               y_label=\"Frequency\", \n                               rotate_x_ticks=0)\n\n\nfig, ax = figure_4(USED_STRESS, False)\nfig.savefig('./figures/figure_4.png', dpi=300, bbox_inches=\"tight\")\n_ = fig.suptitle(\"Fig 4. Breakdown of the literature\")\n\n\n\n\n\n\n\n\n\n\nHow was STRESS used?\nThe guideline have been listed either in main text, or in appendix. Also it might be in the form of checklist, structured (that contains the guidelines’ elements with description), and unstructured (which might contain some elements of the guideline).\n\ndef figure_4(data: pd.DataFrame, figsize: Optional[int|int] = (12,6)):\n    '''Frequency of type of paper\n\n    Type of papers that have used STRESS; which includes journal, conference,\n    workshop, and preprints papers as well as thesis.\n\n    Parameters:\n    ---------\n    data: pd.DataFrame\n        The cleaned + filtered review data to plot\n\n    figsize = Tuple(int, int)\n        Size of matplotlib figure\n        \n    Returns:\n    -------\n    out: fig and axis of plot\n    '''\n\n    freq = data[\"stress_implementation\"].value_counts()\n\n    return frequency_bar_chart(data=freq, \n                               x_label=\"Approach\", \n                               y_label=\"Frequency\", \n                               rotate_x_ticks=90)\n\n\nfig, ax = figure_4(USED_STRESS, False)\nfig.savefig('./figures/figure_4.png', dpi=300, bbox_inches=\"tight\")\n_ = fig.suptitle(\"Fig 4. Frequency of Papers Based on How They Implemented STRESS Guidelines\")\n\n\n\n\n\n\n\n\n\n\nUsage by Journal/conference/other\n\nTM query: Computational Management Science appears twice? small different in raw data recording?\n\n\nTM query: There are 3 univrsity of southampton and 2 Lancaster Uni publications. I think we need to double check that we are not double counting with academic journals or conference papers.\n\n\nJournal_freq = USED_STRESS[\"journal\"].value_counts()\n\nJournal_freq = Journal_freq.reset_index()\nJournal_freq.columns = [\"Journal\", \"Frequency\"]\n\nJournal_freq.set_index([\"Journal\"], inplace=True)\n\n# Print the resulting DataFrame\nJournal_freq\n\n\n\n\n\n\n\n\nFrequency\n\n\nJournal\n\n\n\n\n\nJournal of Simulation\n11\n\n\nWinter Simulation Conference\n6\n\n\nBMJ\n4\n\n\nProceedings of the Operational Research Society Simulation Workshop\n3\n\n\nUniversity of Southampton\n3\n\n\nOperations Research for Health Care\n3\n\n\nLancaster University\n2\n\n\nHealth Care Management Science\n2\n\n\nPlos one\n2\n\n\nJAMA\n2\n\n\nHealth Systems\n2\n\n\nJournal of the Operational Research Society\n2\n\n\nBMC Health Services Research\n2\n\n\nHealthcare\n2\n\n\nIstanbul Business Research\n2\n\n\nmedRxiv\n2\n\n\nInternational Journal of Nursing Studies\n1\n\n\nValue in Health\n1\n\n\nAnesthesiology\n1\n\n\nFrontiers in Oncology\n1\n\n\nHealth and Social Care Delivery Research\n1\n\n\nMedical Decision Making\n1\n\n\nContemporary Clinical Trials\n1\n\n\ncancers\n1\n\n\nPlos Medicine\n1\n\n\narXiv\n1\n\n\nElectronics\n1\n\n\nWater\n1\n\n\nTranslational Lung Cancer Research\n1\n\n\nJournal of Evaluation in Clinical Practice\n1\n\n\nFrontiers in Neurology\n1\n\n\nOSF\n1\n\n\nComputational Management Science\n1\n\n\nCureus\n1\n\n\nStroke\n1\n\n\nNorwegian University of Science and Technology\n1\n\n\nNational University of Irland\n1\n\n\nComputational Management Science\n1\n\n\n\n\n\n\n\n\n\nFull versus partial usage of STRESS sections\n\nTM note - we should provide %’s as well as counts\n\n\nPartially_freq = USED_STRESS[\"partially\"].value_counts()\n\nPartially_freq = Partially_freq.reset_index()\nPartially_freq.columns = [\"Partially?\", \"Frequency\"]\n\n# Print the resulting DataFrame\nPartially_freq\n\n\n\n\n\n\n\n\nPartially?\nFrequency\n\n\n\n\n0\nYes\n45\n\n\n1\nNo\n25\n\n\n2\nDP\n0\n\n\n\n\n\n\n\n\n\nIs the coded model available?\n\nTM note: cannot be shared for confidential reasons. I think this should be recoded to = “No”\n\n\nTM note: will be available in the future should be recoded as “No”\n\n\nCode_Access_freq = USED_STRESS[\"source_code_access\"].value_counts()\n\nplt.figure(figsize=(10, 8))\nSCAB = Code_Access_freq.plot(kind=\"bar\")\n\nplt.title(\"Fig 7. Frequency of Papers based on Type of Source-Code Access\")\nplt.xlabel(\"Type of Access\")\nplt.ylabel(\"Frequency\")\n\n# Add data labels on the bars\nSCAB.bar_label(SCAB.containers[0], label_type=\"edge\", padding=3)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\nHow many of the publications contain at least one author from STRESS 1.0?\n\nTM note - the no target author list seems wrong!\nSomething note right? Should we just be using the manual target field from the dataset that gives the same answer as in the summary?\n\n\ntarget_authors = [\"Monks\", \"Currie\", \"Onggo\", \"Robinson\", \"Kunc\", \"Taylor\"]\n\n\n# def split_publications_by_stress_authors(target_authors):\n#     \"\"\"of\n#     Returns two dataframes.  One contains all publications where at least one\n#     of the authors was a member of the original stress team.  The second\n#     excludes all stress team members.\n#     \"\"\"\n\n#     target_included = []\n#     not_target_authors = []\n\n#     for index, row in USED_STRESS.iterrows():\n#         authors_in_row = row[\"authors\"]\n\n#         # Check for missing or NaN values\n#         if pd.isna(authors_in_row):\n#             not_target_authors.append(\n#                 None\n#             )  # If it's NaN, consider as not_target_authors\n#             continue\n\n#         authors_in_row = authors_in_row.split(\n#             \", \"\n#         )  # Assuming author names are separated by ', '\n\n#         for authors in authors_in_row:\n#             if any(\n#                 target_authors in authors for target_authors in target_authors\n#             ):\n#                 target_included.append(\n#                     row\n#                 )  # Append the entire row's authors to the target_included list\n\n#             else:\n#                 not_target_authors.append(\n#                     row\n#                 )  # Append the entire row's authors to the not_target_authors list\n\n#     df_target_included = pd.DataFrame(target_included, columns=[\"authors\"])\n#     df_not_target_authors = pd.DataFrame(\n#         not_target_authors, columns=[\"authors\"]\n#     )\n#     return df_target_included, df_not_target_authors\n\n\n# # Display the DataFrames\n# print(\n#     f\"Papers including at least one STRESS author: n = {len(df_target_included)}\"\n# )\n\n\n# print(f\"Papers with no STRESS authors n = {len(df_not_target_authors)}\")"
  },
  {
    "objectID": "quarto_site/research_questions.html",
    "href": "quarto_site/research_questions.html",
    "title": "Research Questions (draft)",
    "section": "",
    "text": "Research Questions (draft)\n\nHow many references are using STRESS to document their model versus general citation and discussion (how else has STRESS been used)\nWhat was the uptake of STRESS over time?\nWhat is the breakdown of the literature that used STRESS for DES, SD and ABS?\nHas STRESS been used to document any hybrid simulation models? If so how has it been used (e.g. multiple checklists); have modifications been introduced have alternative guidelines been used?\nWhat are the fields of application where STRESS has been used? (e.g. manufacturing, healthcare etc)\nHow did authors use STRESS to structure their reporting of models?\n\nChecklist supplement pointing to paras, lines etc.\nSections within the main paper or appendix\nOther\nAre there any sections of STRESS that caused authors problems?\n\nHow has each section of STRESS been used? Do any need to be clarified or rephrased?\nAre additional sections or modifications to sections needed to improve model reporting?\nWhat modifications are needed to document a hybrid model?"
  },
  {
    "objectID": "quarto_site/summary.html",
    "href": "quarto_site/summary.html",
    "title": "Summary of early findings (draft)",
    "section": "",
    "text": "Ending in October 2024, we identified and reviewed 171 studies that cited the original STRESS guideline in their reference lists using Google Scholar. After removing duplicates and non-English language articles, 165 unique studies were identified. Of these, 73 (44%) studies explicitly claimed to have used the guideline to report their simulation model. However, only 45 of these studies applied all elements of the guideline. In the remaining 28 studies, certain elements were either partially applied or omitted. For instance, while most studies reported elements such as “objective” and “logic,” many did not fully address “implementation” or “code access,” with some only mentioning parts of the implementation process.\nOf all the studies that used the STRESS guideline, 14 (19%) were authored or co-authored by at least one of the original guideline’s developers.\n\nIn terms of journal distribution, the dataset revealed that papers were published across various journals, primarily focusing on areas related to the healthcare domain (this is further highlighted and discussed in RQ5 and Fig 4). Notable journals included Healthcare Management Science, BMJ, Health Systems, and Health and Social Care Delivery Research. However, the Journal of Simulation was the most frequently cited journal among the studies that employed the STRESS guideline, with 11 papers published in this journal (15%). Following closely was the Winter Simulation Conference, which featured six papers utilizing STRESS.\n\n\n\n\n\n73 studies claimed to use the STRESS guideline to report their simulation work. This could be further break down to:\nFull Use of the STRESS Guideline: 45 studies used all elements of the guideline. Partial Use of the STRESS Guideline: 28 studies applied only some elements.\nFrom the 165 unique studies, subtracting the 73 that claimed to use the guideline leaves 92 studies that cited STRESS in a more general way, without directly using it to document their own models. Some papers cited STRESS to compare it with other simulation reporting framework such as the study by Pawel et al. (2022) and Moallemi et al. (2020). Researchers used STRESS to critique or discuss existing methodologies, offering insights into its strengths or limitations. Furthermore, in a study conducted by Howick et al. (2024), authors offer insights for extending the STRESS to encompass hybrid simulation, with a focus on SD and ABS hybridisation. Moreover, there were 17 literature reviews in the dataset (out of 165 papers), highlighting the guideline being recognised as a key framework in broader discussions within the academic community. Moreover, in a study by Nwanosike (2023), they used the STRESS checklist for assessing the quality of the simulation studies.\n\n\n\nFigure 1 illustrates the number of papers that use STRESS to report a computer simulation model between 2018 and 2024 (part). Examining the studies that used STRESS over time reveals a notable increase in its adoption since its publication in 2019. The highest usage occurred in 2022, with 18 papers out of 73 employing the guideline, followed by 17 papers in both 2021 and 2023. This upward trend demonstrates growing recognition and acceptance of the STRESS guideline within the academic community. This rise may be attributed to the increasing use of simulation studies, where clear reporting standards become essential for transparency and reproducibility. It also highlights the importance of continuing to update and refine the guideline to ensure it meets the evolving needs of simulation researchers.\n\n\n\n\n\n\nFigure 1 No. Publications using STRESS by year\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: No. publications using STRESS by year\n\n\n\n\n\n\n\n\n\nFigure 2 reports the breakdown of simulation methods used in the studies that documented a simulation model. DES was the most commonly used, appearing in 38 papers, followed by ABS in 14 papers. Additionally, seven studies employed hybrid simulation approaches, underscoring the need to extend the guideline to better accommodate the reporting of hybrid simulations. There were also five SD models which used the guideline. Additionally, while the original STRESS guideline did not specifically address reporting for Monte Carlo simulations, six studies employing Monte Carlo simulation have nonetheless utilised the STRESS guideline. Notably, one of these studies found that STRESS-DES was more closely aligned with the principles of Monte Carlo simulation (study no 63, Denz et al., 2023).\n\n\n\n\n\n\nFigure 2 Simulation methods\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: Simulation methods\n\n\n\n\n\n\n\n\n\nYes, STRESS has been utilized to document hybrid simulation models, as evidenced by the seven studies that employed hybrid simulation approaches while referencing the guideline.\n\nThree DES+ABS,\nTwo SD+ABS,\nOne ABS+SD+DES\nand, one Monte Carlo + machine learning\n\nResearchers may have integrated elements from both STRESS and other relevant guidelines to comprehensively report their hybrid models such as the study by Allen et al. (2020) which used TRIPOD protocol for reporting machine learning and STRESS for Monte Carlo.\nSome of these studies have adapted the STRESS guideline to better fit the unique requirements of hybrid simulations, potentially introducing modifications or additional reporting elements tailored to the complexities of these models. For example, in the SD+ABS model of Shukla et al (2022), they employed the guideline in a structured way in the paper’s main text, although not all aspects of their ABS model has been reported (while most of the elements have been reported for SD, only the logic element has been described for ABS).\n\n\n\nFigure 3 reports the breakdown of studies in terms of application area. The STRESS guideline has been predominantly applied in healthcare, with 56 out of 73 studies falling within this domain. These studies encompassed various case studies and operational research problems, including staffing, patient flow, disease transmission, and disease diagnosis. The second application area, after healthcare, is supply chain and operations, which includes sectors such as the food industry, drug industry, mining operations, and supply chain financing. Additionally, a few studies addressed other application areas, including hospitality and tourism, water resource management, business analytics, and geography and environmental science.\n\n\n\n\n\n\nFigure 3 Application area\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: Application area\n\n\n\n\n\n\n\n\n\nThe authors of papers utilising the STRESS guideline were classified based on how they documented their models into three categories: checklist, structured, and unstructured formats. We report the results in Figure 4.\nA. Checklist Format\nThis format was employed in 19 papers, primarily located in the appendix rather than the main text. Most of these papers utilised the same checklist provided in the original STRESS guideline.\nB. Structured Format\nA structured format was identified in 32 papers, where authors provided detailed descriptions referencing all or some of the STRESS elements. This format was predominantly found in the main text, with 26 papers incorporating it there and 6 using it in the appendix.\nC. Unstructured Format\nThe unstructured format was present in 19 papers, where authors mentioned the STRESS elements in a less organised manner. Of these, seven papers included references to the elements in the main text, while 12 did so in the appendix. Locating the STRESS elements in these papers often required additional time and effort due to the lack of systematic organisation.This challenge may hinder reproducibility and transparency of simualtion studies.\nThe prevalence of the checklist format, particularly in the appendix, suggests that researchers value the straightforwardness of this method but may not prioritise its visibility in the main text, possibly due to word count limitations.\n\n\n\n\n\n\nFigure 4 Authors approach to using STRESS within articles\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: Authors approach to using STRESS within articles\n\n\n\n\n\n\n\n\n\nCertain elements of the STRESS guideline, particularly those related to implementation—such as model execution and random sampling—were mentioned less explicitly and less frequently compared to other elements. However, authors did not provide specific reasons for these omissions; many simply neglected to include certain components without justification.\nRegarding the objective element, the aims of the experiments were discussed less frequently across the simulation studies. Similarly, the algorithms and model components within the logic elements received limited reporting, indicating a general lack of emphasis on these foundational aspects.\nIn terms of the data element, while authors predominantly covered data sources and input parameters, assumptions and preprocessing steps were among the most overlooked aspects in simulation reporting. Additionally, the estimation approach outlined in the experimentation elements garnered limited attention from authors.\nFinally, the code access element was referenced in 38 studies that employed the STRESS guideline. A further assessment of the papers that provided a code access statement revealed that most authors shared their source code through links to repositories such as GitHub or included it as an appendix (23 papers). Eleven studies indicated that the code would be available upon request, while a few papers mentioned confidentiality reasons for not sharing the model or stated that they would provide it in future publications.\n\n\n\nTo be determined by consensus from the STRESS review team.\n\n\n\n\n\n\nOne study has mentioned to the need for validation and verification section (Achter et al., 2022).\nGiven the increasing prevalence of hybrid simulations combining various methodologies, there may be a need for dedicated sections addressing the unique reporting requirements for these models. This could include guidelines on integrating different methods and presenting their interactions.\nAdding/ introducing some papers outlining good practices could improve the use of the guideline, particularly, the sections that are under represented in the reports such as those that mentioned in question no 7.\n\n\n\n\n\nThe aim/ reason for hybridisation.\nThe specific components and interactions between them.\nThe data exchange method between the models, interaction rules, and synchronisation.\n\n\n\n\n\nStudy No. 25: Wood et al., 2020: The STRESS study was fully used but not cited - however, it showed up in the cited results!\nStudy No. 43 provides valuable insights for extending the guideline to incorporate hybrid simulation approaches, particularly a conceptual framework for hybrid Agent-Based Modeling and System Dynamics (ABM+SD) models.\nStudy No. 51: Gadomski et al. (2021): The authors claim to have used the guideline, but there is no evidence supporting this claim.\nStudy No. 64: Conlon & Molloy (2023): This study refers to supplementary material for the guideline; however, I could not find the mentioned supplementary section or file.\nStudy No. 113: Saville et al. (2022): The authors did not claimed the use of STRESS but there are some elements of the guideline (it might be due to the fact that the simulation is not the focus of the study instead the classification is)\nStudy No. 115: Birchansky et al. (2021): I doubt that they used STRESS. Except for the name, no elements has been mentioned altough some concepts of the elements are included.\nStudy No. 138: Stokes (2020): Reassessment needed! Although the author claims to have used the guideline, I was unable to locate the elements within the text.\nStudy No. 161: Hajlasz (2023): This thesis is not in English, so analysis has not been conducted. However, it appears that the author may have used the guideline. Further language support is needed for assessment."
  },
  {
    "objectID": "quarto_site/summary.html#overview",
    "href": "quarto_site/summary.html#overview",
    "title": "Summary of early findings (draft)",
    "section": "",
    "text": "Ending in October 2024, we identified and reviewed 171 studies that cited the original STRESS guideline in their reference lists using Google Scholar. After removing duplicates and non-English language articles, 165 unique studies were identified. Of these, 73 (44%) studies explicitly claimed to have used the guideline to report their simulation model. However, only 45 of these studies applied all elements of the guideline. In the remaining 28 studies, certain elements were either partially applied or omitted. For instance, while most studies reported elements such as “objective” and “logic,” many did not fully address “implementation” or “code access,” with some only mentioning parts of the implementation process.\nOf all the studies that used the STRESS guideline, 14 (19%) were authored or co-authored by at least one of the original guideline’s developers.\n\nIn terms of journal distribution, the dataset revealed that papers were published across various journals, primarily focusing on areas related to the healthcare domain (this is further highlighted and discussed in RQ5 and Fig 4). Notable journals included Healthcare Management Science, BMJ, Health Systems, and Health and Social Care Delivery Research. However, the Journal of Simulation was the most frequently cited journal among the studies that employed the STRESS guideline, with 11 papers published in this journal (15%). Following closely was the Winter Simulation Conference, which featured six papers utilizing STRESS."
  },
  {
    "objectID": "quarto_site/summary.html#results-by-research-question",
    "href": "quarto_site/summary.html#results-by-research-question",
    "title": "Summary of early findings (draft)",
    "section": "",
    "text": "73 studies claimed to use the STRESS guideline to report their simulation work. This could be further break down to:\nFull Use of the STRESS Guideline: 45 studies used all elements of the guideline. Partial Use of the STRESS Guideline: 28 studies applied only some elements.\nFrom the 165 unique studies, subtracting the 73 that claimed to use the guideline leaves 92 studies that cited STRESS in a more general way, without directly using it to document their own models. Some papers cited STRESS to compare it with other simulation reporting framework such as the study by Pawel et al. (2022) and Moallemi et al. (2020). Researchers used STRESS to critique or discuss existing methodologies, offering insights into its strengths or limitations. Furthermore, in a study conducted by Howick et al. (2024), authors offer insights for extending the STRESS to encompass hybrid simulation, with a focus on SD and ABS hybridisation. Moreover, there were 17 literature reviews in the dataset (out of 165 papers), highlighting the guideline being recognised as a key framework in broader discussions within the academic community. Moreover, in a study by Nwanosike (2023), they used the STRESS checklist for assessing the quality of the simulation studies.\n\n\n\nFigure 1 illustrates the number of papers that use STRESS to report a computer simulation model between 2018 and 2024 (part). Examining the studies that used STRESS over time reveals a notable increase in its adoption since its publication in 2019. The highest usage occurred in 2022, with 18 papers out of 73 employing the guideline, followed by 17 papers in both 2021 and 2023. This upward trend demonstrates growing recognition and acceptance of the STRESS guideline within the academic community. This rise may be attributed to the increasing use of simulation studies, where clear reporting standards become essential for transparency and reproducibility. It also highlights the importance of continuing to update and refine the guideline to ensure it meets the evolving needs of simulation researchers.\n\n\n\n\n\n\nFigure 1 No. Publications using STRESS by year\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: No. publications using STRESS by year\n\n\n\n\n\n\n\n\n\nFigure 2 reports the breakdown of simulation methods used in the studies that documented a simulation model. DES was the most commonly used, appearing in 38 papers, followed by ABS in 14 papers. Additionally, seven studies employed hybrid simulation approaches, underscoring the need to extend the guideline to better accommodate the reporting of hybrid simulations. There were also five SD models which used the guideline. Additionally, while the original STRESS guideline did not specifically address reporting for Monte Carlo simulations, six studies employing Monte Carlo simulation have nonetheless utilised the STRESS guideline. Notably, one of these studies found that STRESS-DES was more closely aligned with the principles of Monte Carlo simulation (study no 63, Denz et al., 2023).\n\n\n\n\n\n\nFigure 2 Simulation methods\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: Simulation methods\n\n\n\n\n\n\n\n\n\nYes, STRESS has been utilized to document hybrid simulation models, as evidenced by the seven studies that employed hybrid simulation approaches while referencing the guideline.\n\nThree DES+ABS,\nTwo SD+ABS,\nOne ABS+SD+DES\nand, one Monte Carlo + machine learning\n\nResearchers may have integrated elements from both STRESS and other relevant guidelines to comprehensively report their hybrid models such as the study by Allen et al. (2020) which used TRIPOD protocol for reporting machine learning and STRESS for Monte Carlo.\nSome of these studies have adapted the STRESS guideline to better fit the unique requirements of hybrid simulations, potentially introducing modifications or additional reporting elements tailored to the complexities of these models. For example, in the SD+ABS model of Shukla et al (2022), they employed the guideline in a structured way in the paper’s main text, although not all aspects of their ABS model has been reported (while most of the elements have been reported for SD, only the logic element has been described for ABS).\n\n\n\nFigure 3 reports the breakdown of studies in terms of application area. The STRESS guideline has been predominantly applied in healthcare, with 56 out of 73 studies falling within this domain. These studies encompassed various case studies and operational research problems, including staffing, patient flow, disease transmission, and disease diagnosis. The second application area, after healthcare, is supply chain and operations, which includes sectors such as the food industry, drug industry, mining operations, and supply chain financing. Additionally, a few studies addressed other application areas, including hospitality and tourism, water resource management, business analytics, and geography and environmental science.\n\n\n\n\n\n\nFigure 3 Application area\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: Application area\n\n\n\n\n\n\n\n\n\nThe authors of papers utilising the STRESS guideline were classified based on how they documented their models into three categories: checklist, structured, and unstructured formats. We report the results in Figure 4.\nA. Checklist Format\nThis format was employed in 19 papers, primarily located in the appendix rather than the main text. Most of these papers utilised the same checklist provided in the original STRESS guideline.\nB. Structured Format\nA structured format was identified in 32 papers, where authors provided detailed descriptions referencing all or some of the STRESS elements. This format was predominantly found in the main text, with 26 papers incorporating it there and 6 using it in the appendix.\nC. Unstructured Format\nThe unstructured format was present in 19 papers, where authors mentioned the STRESS elements in a less organised manner. Of these, seven papers included references to the elements in the main text, while 12 did so in the appendix. Locating the STRESS elements in these papers often required additional time and effort due to the lack of systematic organisation.This challenge may hinder reproducibility and transparency of simualtion studies.\nThe prevalence of the checklist format, particularly in the appendix, suggests that researchers value the straightforwardness of this method but may not prioritise its visibility in the main text, possibly due to word count limitations.\n\n\n\n\n\n\nFigure 4 Authors approach to using STRESS within articles\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: Authors approach to using STRESS within articles\n\n\n\n\n\n\n\n\n\nCertain elements of the STRESS guideline, particularly those related to implementation—such as model execution and random sampling—were mentioned less explicitly and less frequently compared to other elements. However, authors did not provide specific reasons for these omissions; many simply neglected to include certain components without justification.\nRegarding the objective element, the aims of the experiments were discussed less frequently across the simulation studies. Similarly, the algorithms and model components within the logic elements received limited reporting, indicating a general lack of emphasis on these foundational aspects.\nIn terms of the data element, while authors predominantly covered data sources and input parameters, assumptions and preprocessing steps were among the most overlooked aspects in simulation reporting. Additionally, the estimation approach outlined in the experimentation elements garnered limited attention from authors.\nFinally, the code access element was referenced in 38 studies that employed the STRESS guideline. A further assessment of the papers that provided a code access statement revealed that most authors shared their source code through links to repositories such as GitHub or included it as an appendix (23 papers). Eleven studies indicated that the code would be available upon request, while a few papers mentioned confidentiality reasons for not sharing the model or stated that they would provide it in future publications.\n\n\n\nTo be determined by consensus from the STRESS review team.\n\n\n\n\n\n\nOne study has mentioned to the need for validation and verification section (Achter et al., 2022).\nGiven the increasing prevalence of hybrid simulations combining various methodologies, there may be a need for dedicated sections addressing the unique reporting requirements for these models. This could include guidelines on integrating different methods and presenting their interactions.\nAdding/ introducing some papers outlining good practices could improve the use of the guideline, particularly, the sections that are under represented in the reports such as those that mentioned in question no 7.\n\n\n\n\n\nThe aim/ reason for hybridisation.\nThe specific components and interactions between them.\nThe data exchange method between the models, interaction rules, and synchronisation.\n\n\n\n\n\nStudy No. 25: Wood et al., 2020: The STRESS study was fully used but not cited - however, it showed up in the cited results!\nStudy No. 43 provides valuable insights for extending the guideline to incorporate hybrid simulation approaches, particularly a conceptual framework for hybrid Agent-Based Modeling and System Dynamics (ABM+SD) models.\nStudy No. 51: Gadomski et al. (2021): The authors claim to have used the guideline, but there is no evidence supporting this claim.\nStudy No. 64: Conlon & Molloy (2023): This study refers to supplementary material for the guideline; however, I could not find the mentioned supplementary section or file.\nStudy No. 113: Saville et al. (2022): The authors did not claimed the use of STRESS but there are some elements of the guideline (it might be due to the fact that the simulation is not the focus of the study instead the classification is)\nStudy No. 115: Birchansky et al. (2021): I doubt that they used STRESS. Except for the name, no elements has been mentioned altough some concepts of the elements are included.\nStudy No. 138: Stokes (2020): Reassessment needed! Although the author claims to have used the guideline, I was unable to locate the elements within the text.\nStudy No. 161: Hajlasz (2023): This thesis is not in English, so analysis has not been conducted. However, it appears that the author may have used the guideline. Further language support is needed for assessment."
  }
]